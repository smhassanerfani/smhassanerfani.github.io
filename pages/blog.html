<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mohammad H. Erfani - Blog</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>

    <header>
        <nav>
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="publications.html">Publications</a></li>
                <li><a href="conferences.html">Conferences</a></li>
                <li><a href="projects.html">Projects</a></li>
                <li><a href="blog.html">Blog</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <section class="blog">
            <!-- <h1>Blog</h1> -->

            <div class="blog-post">
                <h2>Shallow Water Equations: Numerical Schemes, PINNs, and Friction Parameterization</h2>
                <p class="post-date">Coming Soon</p>
                <div class="post-tags">
                    <span class="tag">Shallow Water Equations</span>
                    <span class="tag">Numerical Schemes</span>
                    <span class="tag">PINNs</span>
                    <span class="tag">Parameterization of Friction Losses</span>
                </div>
                <p class="post-excerpt">
                    A comparative study of solving the shallow water equations using classical numerical schemes 
                    such as Lax and MacCormack versus Physics-Informed Neural Networks (PINNs). The discussion 
                    also explores parameterizing the friction term using conventional approaches (e.g., Manning’s 
                    equation, Darcy–Weisbach, Chezy’s formula) compared to machine learning-based 
                    parameterizations, highlighting trade-offs in accuracy, interpretability, and computational efficiency.
                </p>
                <a class="read-more-btn coming-soon">Read More →</a>
            </div>

            <div class="blog-post">
                <h2>FutureWarning: Democracy Deprecation Notice</h2>
                <p class="post-date">Published on October 3, 2025</p>
                <div class="post-tags">
                    <span class="tag">Politics</span>
                    <span class="tag">Democracy</span>
                    <span class="tag">AI</span>
                    <span class="tag">Governance</span>
                    <span class="tag">Technology</span>
                </div>
                <p class="post-excerpt">
                    Democracy has long been treated as the most "stable release" of political systems which is tested through centuries of trial and error, refined through revolutions, and widely adopted because it worked better than the alternatives. But like any system, its adoption was never purely about ideals. It was, above all, a practical solution to control the problem.
                </p>
                <a href="blog/2025-10-deprecation-warning-democracy.html" class="read-more-btn">Read More →</a>
            </div>
            
            <div class="blog-post">
                <h2>Solving an ODE: Symbolic, Numerical, and PINNs</h2>
                <p class="post-date">Published on October 1, 2025</p>
                <div class="post-tags">
                    <span class="tag">ODEs</span>
                    <span class="tag">SymPy</span>
                    <span class="tag">Euler Method</span>
                    <span class="tag">PINNs</span>
                </div>
                <p class="post-excerpt">
                    A comprehensive comparison of three approaches to solving ordinary differential equations: analytical solutions with SymPy, numerical approximation using Euler's method, and physics-informed neural networks. We solve dy/dt = 2t - y and compare their insights and results.
                </p>
                <a href="blog/2025-10-ode-solving-methods.html" class="read-more-btn">Read More →</a>
            </div>
            
            <div class="blog-post">
                <h2>The Trade-off Between Model Expressivity and Inductive Bias in Machine Learning</h2>
                <p class="post-date">Published on September 24, 2025</p>
                <div class="post-tags">
                    <span class="tag">Machine Learning</span>
                    <span class="tag">Model Theory</span>
                    <span class="tag">Inductive Bias</span>
                </div>
                <p class="post-excerpt">
                    Understanding the balance between model complexity and built-in assumptions is fundamental to successful machine learning. This post explores the critical trade-off between model expressivity and inductive bias, illustrated through simple examples and real-world applications like CNNs vs. Vision Transformers.
                </p>
                <a href="blog/2025-09-expressivity-vs-inductive-bias.html" class="read-more-btn">Read More →</a>
            </div>

        </section>
    </main>

    <footer>
        <p>&copy; 2025 Mohammad H. Erfani. All rights reserved.</p>
    </footer>

</body>
</html>